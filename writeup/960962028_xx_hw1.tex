\documentclass{article} % For LaTeX2e
\usepackage{cos424,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}


\title{ML Genre Classification: \\
\begin{large} Searching for relevant features \end{large} }

\author{\\
\textbf{Rob Whitaker}, 
Physics \\
\texttt{rmw2@princeton.edu} \\
\textbf{Eric Mitchell}, 
Computer Science \\
\texttt{eam6@princeton.edu} \\
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
Guessing the genre of a song from an excerpt is not a simple task.  Human beings with years of music listening experience often disagree about which label ought to be ascribed to a given song.  With this context, the task of teaching a machine to do the same with only a limited number of songs for training seems significantly more challenging than it may at first.  The question we are left to answer, before deciding on a learning model, is what defines the genre of a song?  It's difficult to come up with answers but 

\section{Related Work}
A number of forays have already been made into the field, using a variety of 

\section{Methods}

\subsection{Feature Selection}

We make a number of observations and assumptions to guide and simplify our analysis.  Importantly, there is nothing comparable about corresponding 20ms frames for any two songs.  We assume that the 30-second excerpts from each song are chosen arbitrarily, if not uniformly, from the song's entirety.  Meaningful ways of comparing frame-level features between songs must then account for the song's architecture.  The simpler way of achieving this amounts to treating all frames as identical and summarizing the distributions of the per-frame values, as we did in our basic classifiers.

\section{Results}
PUT FIGURES HERE

\section{Discussion and Conclusion}

\subsubsection*{Acknowledgments}


\bibliography{ref}

\end{document}
